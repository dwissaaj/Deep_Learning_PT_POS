{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer(strip_handles=True)\n",
    "df = pd.read_excel(\"newest data.xlsx\")\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df['text'] = df['text'].fillna('').apply(str)\n",
    "df['text'] = df['text'].replace({'\"':'',\n",
    "                                 '\\d+':'',\n",
    "                                 ':':'',\n",
    "                                 ';':'',\n",
    "                                 '#':'',\n",
    "                                 '@':'',\n",
    "                                 '_':'',\n",
    "                                 ',': '',\n",
    "                                 \"'\": '',\n",
    "                                  }, regex=True)\n",
    "\n",
    "df['text'] = df['text'].str.replace(r'[https]+[?://]+[^\\s<>\"]+|www\\.[^\\s<>\"]+[?()]+[(??)]+[)*]+[(\\xa0]+[-&gt...]', \"\",regex=True)\n",
    "\n",
    "df['text'] = df['text'].replace('\\n','', regex=True)\n",
    "\n",
    "df['text'] = df['text'].replace({'\\.':'','(/)':'','\\(':'','\\)':''},regex=True)\n",
    "df['text'] = df['text'].replace('[\\.:\"]','',regex =True)\n",
    "\n",
    "df['text'] = df['text'].fillna('').apply(str)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df['text'].astype(str)\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",  # Search for all non-letters\n",
    "                          \" \",          # Replace all non-letters with spaces\n",
    "                          str(df['text']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   nomor                                               text  sentimen\n0    1.0  ayo jawab siapa yg baru tau kalau pos indonesi...       3.0\n1    2.0  oktober memperingati hari kesaktian pancasila ...       3.0\n2    3.0  alasan sederhana mau coba download adl dalam r...       3.0\n3    4.0  tercatat sampai dengan semester i pertumbuhan ...       3.0\n4    5.0  digitalisasi di tubuh pt pos indonesia diwujud...       3.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nomor</th>\n      <th>text</th>\n      <th>sentimen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>ayo jawab siapa yg baru tau kalau pos indonesi...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>oktober memperingati hari kesaktian pancasila ...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>alasan sederhana mau coba download adl dalam r...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>tercatat sampai dengan semester i pertumbuhan ...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>digitalisasi di tubuh pt pos indonesia diwujud...</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.strip()\n",
    "df['text'] = df['text'].str.lower()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence),deacc=True))\n",
    "\n",
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)\n",
    "\n",
    "def depure_data(data):\n",
    "\n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "\n",
    "    return data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df['sentimen'] = df['sentimen'].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-27 08:30:08.310842: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-27 08:30:08.310886: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def convert(score):\n",
    "    if score == 3:\n",
    "        return \"Positive\"\n",
    "    elif score == 2:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "df['sentimens'] = df['sentimen'].apply(convert)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   nomor                                               text  sentimen  \\\n0    1.0  ayo jawab siapa yg baru tau kalau pos indonesi...         3   \n1    2.0  oktober memperingati hari kesaktian pancasila ...         3   \n2    3.0  alasan sederhana mau coba download adl dalam r...         3   \n\n  sentimens  \n0  Positive  \n1  Positive  \n2  Positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nomor</th>\n      <th>text</th>\n      <th>sentimen</th>\n      <th>sentimens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>ayo jawab siapa yg baru tau kalau pos indonesi...</td>\n      <td>3</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>oktober memperingati hari kesaktian pancasila ...</td>\n      <td>3</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>alasan sederhana mau coba download adl dalam r...</td>\n      <td>3</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n",
      "104\n",
      "508\n"
     ]
    }
   ],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "X = tokenizer.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X)\n",
    "print(df[ df['sentimens'] == 'Positive'].size)\n",
    "print(df[ df['sentimens'] == 'Negative'].size)\n",
    "print(df[ df['sentimens'] == 'Neutral'].size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-27 08:30:12.608112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-27 08:30:12.608165: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-27 08:30:12.608198: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (levi-Aspire-A315-41): /proc/driver/nvidia/version does not exist\n",
      "2021-10-27 08:30:12.609308: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 48, 150)           300000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 48, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               280800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 581,403\n",
      "Trainable params: 581,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 150\n",
    "lstm_out = 200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 48) (231, 3)\n",
      "(99, 48) (99, 3)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['sentimens']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 50)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-27 08:30:13.186714: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch 3/20\n",
      "Epoch 4/20\n",
      "Epoch 5/20\n",
      "Epoch 6/20\n",
      "Epoch 7/20\n",
      "Epoch 8/20\n",
      "Epoch 9/20\n",
      "Epoch 10/20\n",
      "Epoch 11/20\n",
      "Epoch 12/20\n",
      "Epoch 13/20\n",
      "Epoch 14/20\n",
      "Epoch 15/20\n",
      "Epoch 16/20\n",
      "Epoch 17/20\n",
      "Epoch 18/20\n",
      "Epoch 19/20\n",
      "Epoch 20/20\n",
      "{'verbose': 3, 'epochs': 20, 'steps': 8}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "history = model.fit(X_train, Y_train, epochs = 20, batch_size=batch_size, verbose = 3)\n",
    "print(history.params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 48) (231, 3)\n",
      "(99, 48) (99, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 1s - loss: 1.7138 - accuracy: 0.4898\n",
      "score: 1.71\n",
      "acc: 0.49\n"
     ]
    }
   ],
   "source": [
    "validation_size = 50\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 1],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 0, 1],\n       [1, 0, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 1, 0],\n       [1, 0, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       [1, 0, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 1, 0],\n       [1, 0, 0],\n       [0, 1, 0],\n       [0, 1, 0]], dtype=uint8)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct,net_cnt,net_correct = 0, 0, 0, 0 , 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),\n",
    "                           batch_size=1,verbose = 3)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_acc 68.75 %\n",
      "neg_acc 100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   1   2 122]]\n",
      "1/1 - 0s\n"
     ]
    }
   ],
   "source": [
    "twt = ['pos indonesia jelek banget']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}